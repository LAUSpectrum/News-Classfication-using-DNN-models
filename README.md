There are six Ipython Notebooks (3 models for each dataset) in the submission. These can be found in the folder "Ipython Notebooks". They also have respective HTML files.

The dataset, GloVe Data model embeddings and final model weights are included in the following folder - "Files to be added to your drive" https://drive.google.com/drive/folders/15A2b8uNEfak_1Gfh-c85dTtOHJrfrk7h?usp=sharing
You have to add all these files to your drive in order to run the code. You select all and add at once. This is required to run the code on google colab.

Dataset can also be found on - http://mlg.ucd.ie/datasets/bbc.html

2nd Dataset was imported directly from scikit-learn's dataset library. It does not need to be uploaded/added

glove embeddings can also be found on - http://nlp.stanford.edu/data/glove.6B.zip

Next, open any of the Ipython Notebooks through google colab (you can use the open in colab link to do so)

Execute the cells as required. The colab environment has all the packages installed. The files also contain statements to add dependencies required.

You can find the video, report, presentation and contributions here - https://drive.google.com/drive/folders/1heicqQYsABXzKG3KLB8uVJ117qJ_jHkm?usp=sharing

We have also added a copy of weights, plots, code and architecture in separate folders for each dataset.